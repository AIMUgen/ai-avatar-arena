# **App Name**: AI Avatar Arena

## Core Features:

- LLM Provider Integration: Connects to multiple LLM providers (Google, OpenAI, OpenRouter with free models). Allows selecting specific models for each avatar. Saves API keys and settings for reuse.
- Avatar Simulation Engine: Visualizes avatars in a simulated environment. Allows adding/removing avatars (min 2). Enables turn-based and time-based simulation with a toggle. Implements rate limits configurable per avatar.
- Interactive Environment Editor: Provides a customizable simulation board with resizing, obstacle placement/removal, object placement with custom note descriptions. Includes reset and pause functions.
- Configurable Eyesight Simulation: Simulates avatar eyesight as a 180-degree circular section with adjustable radius, visualized in the simulation.
- LLM-Orchestrated Avatar Actions: LLM-driven avatar actions including turn right/left (30-degree increments), move forward/backward, interact with objects (retrieve custom notes), and interact with other avatars (initiate/join/refuse conversations).
- LLM-Driven Avatar Conversations: Enables avatar-to-avatar conversations managed by LLMs, including initiating, accepting/refusing, engaging, disengaging, and displaying conversation text. Avatars are unaware they are interacting with another AI.
- LLM Reflection and System Prompts: Allows LLMs to issue a 'think' action for reflection, generating a thought output. Uses a system prompt instructing LLMs to act as humans in a virtual world, customizable per avatar with a 'set to default' option.

## Style Guidelines:

- Primary color: Dark blue (#1A237E) for a sophisticated and immersive feel.
- Secondary color: Light gray (#EEEEEE) for clean backgrounds and interface elements.
- Accent: Teal (#00BCD4) for interactive elements and highlights.
- Clean, card-based layout for settings and information displays.
- Use minimalist and clear icons for actions and settings.
- Subtle transitions and animations for a smooth user experience.

## Original User Request:
create a plan for the following application: 1) ap would connect wioth selected llm providers (option to use providers from google, openai and openrouter and few of their newest models - for openrouter I want free ones) 2) app would have a visualization of two avatars (but more could be easily added) which would be guided by llm in this way-> each avatar would collect data from the simulated environement (nicely visualized for the user to see) and return information to llm along with instructions including possible actions -> llm shoould make own decisions what it could do. applicaiton would be turn based (1 turn, 1 action of each llm, one llm cannot make more than one turns within the global turn. the app should have both options - turn based and time based - changable on click. In time based, avatars could move independently (here one could be quicker than the other, depending on the actual llm model). add rate limits and they should also be easily cinfigurable, individidually per each avatar. avatars should also have onfigurable eysight simulation, also easily configurable -> eyesight should be a 180 circle section with easily adjustable radius, visualized in the simulation visualizer. app should have posisiblity to add or remove obstacles on the vizualizing board, resizing the board, resetting the app, pausing. To simplyfy, movement coud be done in each 30 degrees (so not 90 degree turn but 30 degree turn) possible actions should be: turn right, turn left, move forward, move backward, interact with object present in an eyesight which would return to llm cojtent of custom note desctibing object (apart from adding obstacles, it hsould be possible to add objects - can look the same to each other, but objects would have a custom desctiprion notes, to be filled out on clicking on an object. if user doesnt write custom note, it shoud say 'an object'. Otherwise it can say whatever) or interact with another avatar in eyesioght (if llm issues that command, another llm commanding another avatar should get request to join conversation - if refused- llm initiatingconversation should get refusal and both should just resume what they were doing (could also reengage). If llm confirms joinning conversation, both should be in conversation mode and writing to each other - none should know that the other is not a human. conversation should take place until any of then issues disengage from conversation command. Last actoion for llm could be to 'think' -> such action should allow llm to issue a thought as 1 action - to allow it to reflect.  LLM's should have a system promt commanding them to act as humans an d being informed that their are interacting in virtual world with other humans and object and can do anything they like. System prompt tio each avatar should be accessible separately on click from settings. the default one should be hardcoded and could be set anytime by clicking on 'set to default' but otherwise, user could adjust system prompt at will. it whoult be possible for app to save all the settings for another app instances, including api keys for llm providers (in json) so that thy ouwld preload on app start. to recap, each or right the  so each avatar should have individual settings for llm provider, model ,rate limit, system prompt and it sjould be possible to add or remove avatars (min number is 2). // organize first my ideas. then reflect on them and return your analysis on feasibility and how it coould be done.
  